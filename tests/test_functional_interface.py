# model = AutoModelForSeq2SeqLM.from_pretrained("google-t5/t5-base")
# tokenizer = AutoTokenizer.from_pretrained("google-t5/t5-base")


def test_generate():
    # context = "Translate English to German: My name is Wolfgang and I live in Berlin"
    # model_inputs = tokenizer(context, return_tensors="pt")
    # ults.generate(model=model, model_inputs=model_inputs, max_tokens=40)
    pass
